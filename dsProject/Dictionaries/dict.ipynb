{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Q1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You are charge of a dataset that contains the operational state of your company's servers clusters. The Clusters dictionary contains information about which servers belong each cluster.  Below, cluster \"A\" includes servers 1, 2, and 3.  The Servers dictionary contains information about the operational state of each server.  The state will be 0 if the server is in a failed state and 1 if the server is in a successful state. Some of the servers are shared among multiple clusters. Below, server 4 is state 0, meaning it is in a failed state.\n",
    "\n",
    "\n",
    "\n",
    "Write code to return the number of clusters that have at least 1 server in a failed state. Your code should accept a list of clusters as input.\n",
    "\n",
    "\n",
    "\n",
    "Clusters\n",
    "\n",
    "{\n",
    "\n",
    "\"A\": [1, 2, 3],\n",
    "\n",
    "\"B\": [3, 4, 5],\n",
    "\n",
    "\"C\": [2, 4, 6]\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "Servers\n",
    "\n",
    "{\n",
    "\n",
    "1: 1,\n",
    "\n",
    "2: 1,\n",
    "\n",
    "3: 1,\n",
    "\n",
    "4: 0,\n",
    "\n",
    "5: 0,\n",
    "\n",
    "6: 1,\n",
    "\n",
    "}\n",
    "Example 1:\n",
    "\n",
    "Input: [\"A\", \"B\", \"C\"]\n",
    "\n",
    "Output: 2\n",
    "\n",
    "\n",
    "\n",
    "Cluster A contains servers 1, 2, and 3.  Servers 1, 2, and 3 all have a state of 1, meaning none of them are failed. Cluster A should not be included in our count.\n",
    "\n",
    "Cluster B contains servers 3, 4, and 5.  Servers 4, and 5 are in a failed state. Cluster B should be included in our count. Even though there are 2 failed servers in Cluster B, we should only increase our count by 1.\n",
    "\n",
    "Cluster C contains servers 2, 4, and 6. Server 4 is in a failed state. Cluster C should be included our count.\n",
    "\n",
    "\n",
    "\n",
    "Example 2:\n",
    "\n",
    "Input: [\"A\"]\n",
    "\n",
    "Output: 0\n",
    "\n",
    "\n",
    "\n",
    "Cluster A contains servers 1, 2, and 3.  Servers 1, 2, and 3 all have a state of 1, meaning none of them are failed. Cluster A should not be included in our count."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "Clusters = {\n",
    "    \"A\": [1, 2, 3],\n",
    "    \"B\": [3, 4, 5],\n",
    "    \"C\": [2, 4, 6]\n",
    "}\n",
    "Servers = {\n",
    "    1: 1,\n",
    "    2: 1,\n",
    "    3: 1,\n",
    "    4: 0,\n",
    "    5: 0,\n",
    "    6: 1,\n",
    "}\n",
    "my_list = [\"A\", \"B\", \"C\"]\n",
    "def check_cluster(cluster_list : list, clusters, servers) ->int :\n",
    "    failed_clusters = 0\n",
    "    for cluster in cluster_list:\n",
    "        for server in clusters[cluster]:\n",
    "            if Servers[server] == 0:\n",
    "                failed_clusters += 1\n",
    "                break\n",
    "    return failed_clusters\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "print(check_cluster(my_list, Clusters, Servers))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Q2"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Your company owns a video watching platform.  Users can click to start to play the video and click stop to pause the video.  Your team is creating a real time dashboard to display the average viewing time of the users.  The data comes to you as as streaming data and includes a session_id, start_time (unix), and stop_time (unix). The viewing time would be calculated as the stop_time - start_time.  The dashboard requires the average viewing time over all time.\n",
    "\n",
    "\n",
    "\n",
    "Write code to store and retrieve the required data efficiently. When the average viewing time is queried, it must return a result in near real time. You can assume the records will come 1 at a time and there will not be any duplicates.\n",
    "\n",
    "\n",
    "\n",
    "Example 1:\n",
    "\n",
    "Input:\n",
    "\n",
    "{\n",
    "\n",
    "{\"session_id\": 1, \"start_time\": 1626822000, \"stop_time\": 1626823200},\n",
    "\n",
    "{\"session_id\": 1, \"start_time\": 1626823500, \"stop_time\": 1626823800},\n",
    "\n",
    "{\"session_id\": 2, \"start_time\": 1626822600, \"stop_time\": 1626825600},\n",
    "\n",
    "{\"session_id\": 3, \"start_time\": 1626823800, \"stop_time\": 1626824700}\n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "Output:\n",
    "\n",
    "1350\n",
    "\n",
    "\n",
    "\n",
    "The viewing time for each record is calculated as stop_time - start_time.  The average viewing time is the sum of the viewing time divided by the total number of records. The calculation should be: ((1626823200 - 1626822000) + (1626823800 - 1626823500) + (1626825600 - 1626822600) + (1626824700 - 1626823800))/4. This yields the above output."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mTypeError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[7], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m Input \u001B[38;5;241m=\u001B[39m {\n\u001B[0;32m      2\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msession_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1626822000\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1626823200\u001B[39m},\n\u001B[0;32m      3\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msession_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1626823500\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1626823800\u001B[39m},\n\u001B[0;32m      4\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msession_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m2\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1626822600\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1626825600\u001B[39m},\n\u001B[0;32m      5\u001B[0m     {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124msession_id\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m3\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstart_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1626823800\u001B[39m, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mstop_time\u001B[39m\u001B[38;5;124m\"\u001B[39m: \u001B[38;5;241m1626824700\u001B[39m}\n\u001B[0;32m      6\u001B[0m }\n\u001B[0;32m      7\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mavg_view_time\u001B[39m(given_dict):\n\u001B[0;32m      8\u001B[0m     start \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n",
      "\u001B[1;31mTypeError\u001B[0m: unhashable type: 'dict'"
     ]
    }
   ],
   "source": [
    "avg_dict = {\"sum\": 0, \"count\": 0}\n",
    "\n",
    "def store(event):\n",
    "    start_time = event[\"start_time\"]\n",
    "    stop_time = event[\"stop_time\"]\n",
    "\n",
    "    view_time = stop_time - start_time\n",
    "\n",
    "    avg_dict[\"sum\"] += view_time\n",
    "    avg_dict[\"count\"] += 1\n",
    "\n",
    "def retrieve():\n",
    "    avg_time = avg_dict[\"sum\"]/avg_dict[\"count\"]\n",
    "    return avg_time"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def calculate_average_difference(dictionary, start_key, stop_key):\n",
    "    differences = []\n",
    "    for key, value in dictionary.items():\n",
    "        if key == start_key:\n",
    "            start_value = value\n",
    "        elif key == stop_key:\n",
    "            stop_value = value\n",
    "            difference = stop_value - start_value\n",
    "            differences.append(difference)\n",
    "        elif isinstance(value, dict):\n",
    "            nested_differences = calculate_average_difference(value, start_key, stop_key)\n",
    "            differences.extend(nested_differences)\n",
    "    return differences\n",
    "\n",
    "def calculate_average(differences):\n",
    "    if len(differences) > 0:\n",
    "        return sum(differences) / len(differences)\n",
    "    else:\n",
    "        return None"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}